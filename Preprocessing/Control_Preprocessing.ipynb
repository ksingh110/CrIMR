{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfafHFV01sX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "import random\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qwrthST01sZ"
      },
      "source": [
        "Function to fetch CRY1 gene sequence from UCSC API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsXRLtoN01sb"
      },
      "outputs": [],
      "source": [
        "def get_CRY1_gene():\n",
        "    response = requests.get(\"https://api.genome.ucsc.edu/getData/sequence?genome=hg38;chrom=chr12;start=106991364;end=107093549\")\n",
        "    if response.status_code == 200:\n",
        "        return response.json().get(\"dna\", \"\").upper()\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRgDYCgM01sb"
      },
      "source": [
        "One-hot encode sequence and return a 1D array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DOLR_XZ01sc"
      },
      "outputs": [],
      "source": [
        "def onehotencoder(fasta_sequence, max_length=102500):\n",
        "    sequence_array = np.array(list(fasta_sequence))\n",
        "    label_encoder = LabelEncoder()\n",
        "    integer_encoded = label_encoder.fit_transform(sequence_array)\n",
        "    onehotencoder = OneHotEncoder(sparse_output=False, dtype=np.float32)\n",
        "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "    onehot_sequence = onehotencoder.fit_transform(integer_encoded).astype(np.float32)\n",
        "\n",
        "    if onehot_sequence.shape[0] < max_length:\n",
        "        pad_size = max_length - onehot_sequence.shape[0]\n",
        "        padding = np.zeros((pad_size, onehot_sequence.shape[1]))\n",
        "        onehot_sequence = np.vstack([onehot_sequence, padding])\n",
        "    else:\n",
        "        onehot_sequence = onehot_sequence[:max_length, :]\n",
        "    return onehot_sequence.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr-JJvpQ01sc"
      },
      "source": [
        "Augment sequence by introducing substitutions, deletions, or insertions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGZnNVE901sc"
      },
      "outputs": [],
      "source": [
        "def augment_sequence(seq, mutation_rate=0.1):\n",
        "    \"\"\"\n",
        "    Randomly mutates a subset of the sequence.\n",
        "    - `mutation_rate`: Fraction of positions to mutate (default 10% of sequence).\n",
        "    \"\"\"\n",
        "    random.seed(os.urandom(4))  # Ensure true randomness per sequence\n",
        "\n",
        "    seq_list = list(seq)\n",
        "    num_mutations = int(len(seq_list) * mutation_rate)\n",
        "\n",
        "    for _ in range(num_mutations):\n",
        "        idx = random.randint(0, len(seq_list) - 1)\n",
        "        mutation_type = random.choice([\"substitution\", \"deletion\", \"insertion\"])\n",
        "\n",
        "        if mutation_type == \"substitution\":\n",
        "            seq_list[idx] = random.choice([\"A\", \"G\", \"C\", \"T\"])\n",
        "        elif mutation_type == \"deletion\":\n",
        "            del seq_list[idx]\n",
        "        elif mutation_type == \"insertion\":\n",
        "            seq_list.insert(idx, random.choice([\"A\", \"G\", \"C\", \"T\"]))\n",
        "\n",
        "    return ''.join(seq_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sgj0E0IY01sd"
      },
      "source": [
        "Process augmented sequence and save to output file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHvHucYv01sd"
      },
      "outputs": [],
      "source": [
        "def process_data_augmentation(cry1_seq, output_path, num_augmented_sequences=1250, batch_size=250):\n",
        "    \"\"\"\n",
        "    Augments sequences, ensuring diversity, and saves them in batches.\n",
        "    - `num_augmented_sequences`: Total number of augmented sequences to generate.\n",
        "    - `batch_size`: Number of sequences to save in one batch.\n",
        "    \"\"\"\n",
        "    # Load existing data if available\n",
        "    if os.path.exists(output_path):\n",
        "        existing_data = np.load(output_path, allow_pickle=True)[\"arr_0\"].tolist()\n",
        "    else:\n",
        "        existing_data = []\n",
        "\n",
        "    seq_count = 0\n",
        "    rows_save = []\n",
        "\n",
        "    while seq_count < num_augmented_sequences:\n",
        "        augmented_seq = augment_sequence(cry1_seq)\n",
        "\n",
        "        # Ensure augmented sequence is unique\n",
        "        if not is_duplicate(augmented_seq, existing_data):\n",
        "            print(f\"Processed augmented sequence {seq_count + 1}.\")\n",
        "            encoded_seq = onehotencoder(augmented_seq)\n",
        "            seq_count += 1\n",
        "            rows_save.append(encoded_seq)\n",
        "\n",
        "            if len(rows_save) >= batch_size:\n",
        "                existing_data.extend(rows_save)\n",
        "                np.savez_compressed(output_path, arr_0=np.array(existing_data))\n",
        "                rows_save = []\n",
        "\n",
        "    # Save remaining data\n",
        "    if rows_save:\n",
        "        existing_data.extend(rows_save)\n",
        "        np.savez_compressed(output_path, arr_0=np.array(existing_data))\n",
        "\n",
        "    print(f\"Processed {seq_count} augmented sequences and saved to {output_path}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0yY8fler2yb5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4lQaoS001sd"
      },
      "source": [
        "Path to output file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTY2tdJj01se"
      },
      "outputs": [],
      "source": [
        "output_file = \"E:\\\\datasets\\\\processeddata\\\\AUGMENTED_DATA_TRAINING_1250_NEW.npz\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLPIAs0a01se"
      },
      "source": [
        "Fetch CRY1 sequence and process data with augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1yS6FsC01se"
      },
      "outputs": [],
      "source": [
        "cry1_seq = get_CRY1_gene()\n",
        "if cry1_seq:\n",
        "    process_data_augmentation(cry1_seq, output_file)\n",
        "else:\n",
        "    print(\"Failed to fetch CRY1 gene sequence.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}