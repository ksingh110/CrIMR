{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "mutated_data = np.load(\"/content/MUTATION_DATA_TRAINING_6000.npz\", allow_pickle=True)\n",
        "mutated_test = mutated_data['arr_0'][:1000]\n",
        "output_test = \"MUTATED_DATA_TEST_1000_6000\"\n",
        "np.savez_compressed(output_test, arr_0=np.array(mutated_test))\n",
        "mutated_val = mutated_data['arr_0'][5000:]\n",
        "output_val = \"MUTATED_DATA_VAL_1000_6000\"\n",
        "np.savez_compressed(output_val, arr_0=np.array(mutated_val))\n",
        "mutated_train = mutated_data['arr_0'][1000:5000]\n",
        "output_train = \"MUTATED_DATA_TRAIN_5000_6000\"\n",
        "np.savez_compressed(output_train, arr_0=np.array(mutated_train))\n",
        "\n"
      ],
      "metadata": {
        "id": "BbJ82VnD4obt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import tensorflow as tf\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "def load_sequences(data):\n",
        "    encoded_sequences = None\n",
        "    for key in data.files:\n",
        "        temp_sequences = data[key]\n",
        "        if temp_sequences.ndim == 2:\n",
        "            num_samples = temp_sequences.shape[0]\n",
        "            sequence_length = temp_sequences.shape[1] // 4\n",
        "            temp_sequences = np.expand_dims(temp_sequences, axis=1)\n",
        "        if temp_sequences.ndim == 3:\n",
        "            encoded_sequences = temp_sequences\n",
        "            break\n",
        "    return encoded_sequences\n",
        "\n",
        "def load_sequences_with_shape(data):\n",
        "    encoded_sequences = None\n",
        "    for key in data.files:\n",
        "        temp_sequences = data[key]\n",
        "        if temp_sequences.ndim == 2:  # If 2D, reshape to 3D for LSTM\n",
        "            temp_sequences = np.expand_dims(temp_sequences, axis=1)  # (samples, 1, features)\n",
        "        if temp_sequences.ndim == 3:\n",
        "            encoded_sequences = temp_sequences\n",
        "            input_shape = input_shape=(encoded_sequences.shape[1], encoded_sequences.shape[2])\n",
        "            break\n",
        "    return encoded_sequences, input_shape\n",
        "mutated_data = np.load(\"/content/MUTATION_DATA_TRAINING_6000.npz\", allow_pickle=True)\n",
        "nonmutated_data = np.load(\"/content/AUGMENTED_DATA_TRAINING_6000_TRUE.npz\", allow_pickle=True)\n",
        "\n",
        "mutated_sequences, shape = load_sequences_with_shape(mutated_data)\n",
        "nonmutated_sequences, shape = load_sequences_with_shape(nonmutated_data)\n",
        "\n",
        "mutated_test_1 = np.load(\"/content/MUTATED_DATA_TEST_1000_6000.npz\", allow_pickle=True)\n",
        "mutated_test = load_sequences(mutated_test_1)\n",
        "mutated_test_label = np.ones(mutated_test.shape[0])\n",
        "mutated_test, mutated_test_label = shuffle(mutated_test, mutated_test_label, random_state=42)\n",
        "\n",
        "mutated_val_1 = np.load(\"/content/MUTATED_DATA_VAL_1000_6000.npz\", allow_pickle=True)\n",
        "mutated_val = load_sequences(mutated_val_1)\n",
        "mutated_val_label = np.ones(mutated_val.shape[0])\n",
        "mutated_val, mutated_val_label = shuffle(mutated_val, mutated_val_label, random_state=42)\n",
        "\n",
        "mutated_train_1 = np.load(\"/content/MUTATED_DATA_TRAIN_5000_6000.npz\", allow_pickle=True)\n",
        "mutated_train = load_sequences(mutated_train_1)\n",
        "mutated_train_label = np.ones(mutated_train.shape[0])\n",
        "mutated_train, mutated_train_label = shuffle(mutated_train, mutated_train_label, random_state=42)\n",
        "\n",
        "nonmutated_test_1 = np.load(\"/content/AUGMENTED_DATA_TEST_1000_6000.npz\", allow_pickle=True)\n",
        "nonmutated_test = load_sequences(nonmutated_test_1)\n",
        "nonmutated_test_label = np.zeros(nonmutated_test.shape[0])\n",
        "nonmutated_test, nonmutated_test_label = shuffle(nonmutated_test, nonmutated_test_label, random_state=42)\n",
        "\n",
        "nonmutated_val_1 = np.load(\"/content/AUGMENTED_DATA_TEST_VAL_1000_6000.npz\", allow_pickle=True)\n",
        "nonmutated_val = load_sequences(nonmutated_val_1)\n",
        "nonmutated_val_label = np.zeros(nonmutated_val.shape[0])\n",
        "nonmutated_val, nonmutated_val_label = shuffle(nonmutated_val, nonmutated_val_label, random_state=42)\n",
        "\n",
        "nonmutated_train_1 = np.load(\"/content/AUGMENTED_DATA_TRAIN_5000_6000.npz\", allow_pickle=True)\n",
        "nonmutated_train = load_sequences(nonmutated_train_1)\n",
        "nonmutated_train_label = np.zeros(nonmutated_train.shape[0])\n",
        "nonmutated_train, nonmutated_train_label = shuffle(nonmutated_train, nonmutated_train_label, random_state=42)\n",
        "\n",
        "X_val = np.concatenate([mutated_val, nonmutated_val], axis = 0)\n",
        "y_val = np.concatenate([mutated_val_label, nonmutated_val_label], axis = 0)\n",
        "X_val, y_val = shuffle(X_val, y_val, random_state=1)\n",
        "\n",
        "X_test = np.concatenate([mutated_test, nonmutated_test], axis = 0)\n",
        "y_test = np.concatenate([mutated_test_label, nonmutated_test_label], axis = 0)\n",
        "X_test, y_test = shuffle(X_test, y_test, random_state=1)\n",
        "\n",
        "X_train = np.concatenate([mutated_train, nonmutated_train], axis = 0)\n",
        "y_train = np.concatenate([mutated_train_label, nonmutated_train_label], axis = 0)\n",
        "X_train, y_train = shuffle(X_train, y_train, random_state=1)\n"
      ],
      "metadata": {
        "id": "MtMHBJ4naiI5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Compute class weights for imbalanced dataset\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Print to verify\n",
        "print(\"Class Weights:\", class_weight_dict)"
      ],
      "metadata": {
        "id": "BCsX8brQdiHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19f7e600-72a3-44a7-d897-a2a8856e94a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: {0: 1.0, 1: 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "flat_control_data = nonmutated_val.flatten()\n",
        "flat_mutated_data = mutated_val.flatten()\n",
        "\n",
        "# Plotting histograms for comparison\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot histogram for control data\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(flat_control_data, bins=50, kde=True, color=\"blue\")\n",
        "plt.title(\"Control Data (Non-mutated)\")\n",
        "plt.xlabel(\"Feature Values\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "\n",
        "# Plot histogram for mutated data\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(flat_mutated_data, bins=50, kde=True, color=\"red\")\n",
        "plt.title(\"Mutated Data\")\n",
        "plt.xlabel(\"Feature Values\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D1ErNGR_EIB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM, GRU, Dropout, Dense, BatchNormalization"
      ],
      "metadata": {
        "id": "fuMvCck7oj2Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "def rnn_model(input_shape):\n",
        "    model = Sequential([\n",
        "\n",
        "        # First LSTM Layer\n",
        "        LSTM(128, input_shape=input_shape, return_sequences=True, activation=\"relu\"),  # Reduced L2 regularization strength\n",
        "\n",
        "\n",
        "        # Second LSTM Layer\n",
        "        LSTM(64, activation=\"relu\", return_sequences=True),  # Reduced L2 regularization strength\n",
        "\n",
        "        # Third LSTM Layer\n",
        "        LSTM(32, activation=\"relu\", return_sequences=False),  # Reduced L2 regularization strength\n",
        "\n",
        "        Dense(1, activation=\"relu\"),  # Smaller dense layer\n",
        "\n",
        "        Dropout(0.4),        # Output Layer\n",
        "        Dense(1, activation=\"sigmoid\", kernel_regularizer=keras.regularizers.L2(0.01))  # Output layer with L2\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "def reset_rnn(input_shape):\n",
        "    # Recreate the model to reset weights\n",
        "    model = rnn_model(input_shape)\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "checkpoint_path = \"E:/my_models/6000_2_if_new_best_model.weights.h5\"\n",
        "\n",
        "model1 = reset_rnn(shape)\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=True, save_weights_only=True, verbose=1)\n",
        "csv_logger = CSVLogger(\"training_log_6000_2.csv\")\n",
        "\n",
        "history = model1.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
        "                    epochs=100, batch_size=32, callbacks=[checkpoint, csv_logger])\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model1.predict(X_test)\n",
        "y_pred_classes = (y_pred > 0.5).astype(\"int32\")\n",
        "\n",
        "# Evaluate model performance\n",
        "print(classification_report(y_test, y_pred_classes))\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(f\"ROC-AUC: {roc_auc}\")\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color=\"blue\", label=f\"ROC curve (AUC = {roc_auc:.5f})\")\n",
        "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Receiver Operating Characteristic Curve\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Test Accuracy\n",
        "loss, accuracy = model1.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Predictions\n",
        "predictions = model1.predict(X_test).flatten()\n",
        "print(\"\\n🔹 First 10 Predictions vs Actual Values 🔹\")\n",
        "for i in range(10):\n",
        "    print(f\"Sample {i+1}: Actual = {y_test[i]}, Predicted Probability = {predictions[i]:.4f}\")"
      ],
      "metadata": {
        "id": "u28zgozS3RmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1369fe2e-65c8-40a9-b382-fd429359e0bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7482 - loss: 0.5095\n",
            "Epoch 1: val_loss improved from inf to 0.34259, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 1s/step - accuracy: 0.7483 - loss: 0.5094 - val_accuracy: 1.0000 - val_loss: 0.3426\n",
            "Epoch 2/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7974 - loss: 0.4838\n",
            "Epoch 2: val_loss improved from 0.34259 to 0.33666, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 1s/step - accuracy: 0.7974 - loss: 0.4837 - val_accuracy: 1.0000 - val_loss: 0.3367\n",
            "Epoch 3/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8117 - loss: 0.4715\n",
            "Epoch 3: val_loss improved from 0.33666 to 0.33115, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 1s/step - accuracy: 0.8117 - loss: 0.4715 - val_accuracy: 1.0000 - val_loss: 0.3311\n",
            "Epoch 4/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8075 - loss: 0.4724\n",
            "Epoch 4: val_loss improved from 0.33115 to 0.32575, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 1s/step - accuracy: 0.8075 - loss: 0.4724 - val_accuracy: 1.0000 - val_loss: 0.3258\n",
            "Epoch 5/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8068 - loss: 0.4683\n",
            "Epoch 5: val_loss improved from 0.32575 to 0.32056, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 1s/step - accuracy: 0.8068 - loss: 0.4683 - val_accuracy: 1.0000 - val_loss: 0.3206\n",
            "Epoch 6/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7944 - loss: 0.4713\n",
            "Epoch 6: val_loss improved from 0.32056 to 0.31561, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 1s/step - accuracy: 0.7944 - loss: 0.4713 - val_accuracy: 1.0000 - val_loss: 0.3156\n",
            "Epoch 7/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8060 - loss: 0.4672\n",
            "Epoch 7: val_loss improved from 0.31561 to 0.31075, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 1s/step - accuracy: 0.8059 - loss: 0.4672 - val_accuracy: 1.0000 - val_loss: 0.3107\n",
            "Epoch 8/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7979 - loss: 0.4651\n",
            "Epoch 8: val_loss improved from 0.31075 to 0.30606, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 1s/step - accuracy: 0.7979 - loss: 0.4651 - val_accuracy: 1.0000 - val_loss: 0.3061\n",
            "Epoch 9/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7979 - loss: 0.4613\n",
            "Epoch 9: val_loss improved from 0.30606 to 0.30150, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 1s/step - accuracy: 0.7978 - loss: 0.4613 - val_accuracy: 1.0000 - val_loss: 0.3015\n",
            "Epoch 10/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8021 - loss: 0.4652\n",
            "Epoch 10: val_loss improved from 0.30150 to 0.29699, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.8021 - loss: 0.4652 - val_accuracy: 1.0000 - val_loss: 0.2970\n",
            "Epoch 11/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7899 - loss: 0.4615\n",
            "Epoch 11: val_loss improved from 0.29699 to 0.29285, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 1s/step - accuracy: 0.7899 - loss: 0.4614 - val_accuracy: 1.0000 - val_loss: 0.2929\n",
            "Epoch 12/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8043 - loss: 0.4583\n",
            "Epoch 12: val_loss improved from 0.29285 to 0.28839, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 1s/step - accuracy: 0.8042 - loss: 0.4583 - val_accuracy: 1.0000 - val_loss: 0.2884\n",
            "Epoch 13/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7927 - loss: 0.4588\n",
            "Epoch 13: val_loss improved from 0.28839 to 0.28421, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 1s/step - accuracy: 0.7927 - loss: 0.4588 - val_accuracy: 1.0000 - val_loss: 0.2842\n",
            "Epoch 14/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8028 - loss: 0.4469\n",
            "Epoch 14: val_loss improved from 0.28421 to 0.28003, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 1s/step - accuracy: 0.8028 - loss: 0.4469 - val_accuracy: 1.0000 - val_loss: 0.2800\n",
            "Epoch 15/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8057 - loss: 0.4449\n",
            "Epoch 15: val_loss improved from 0.28003 to 0.27593, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 1s/step - accuracy: 0.8057 - loss: 0.4449 - val_accuracy: 1.0000 - val_loss: 0.2759\n",
            "Epoch 16/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7926 - loss: 0.4446\n",
            "Epoch 16: val_loss improved from 0.27593 to 0.27190, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 1s/step - accuracy: 0.7926 - loss: 0.4446 - val_accuracy: 1.0000 - val_loss: 0.2719\n",
            "Epoch 17/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8072 - loss: 0.4370\n",
            "Epoch 17: val_loss improved from 0.27190 to 0.26793, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 1s/step - accuracy: 0.8072 - loss: 0.4370 - val_accuracy: 1.0000 - val_loss: 0.2679\n",
            "Epoch 18/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7913 - loss: 0.4491\n",
            "Epoch 18: val_loss improved from 0.26793 to 0.26426, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 1s/step - accuracy: 0.7914 - loss: 0.4491 - val_accuracy: 1.0000 - val_loss: 0.2643\n",
            "Epoch 19/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7991 - loss: 0.4418\n",
            "Epoch 19: val_loss improved from 0.26426 to 0.26045, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 1s/step - accuracy: 0.7991 - loss: 0.4418 - val_accuracy: 1.0000 - val_loss: 0.2604\n",
            "Epoch 20/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8008 - loss: 0.4427\n",
            "Epoch 20: val_loss improved from 0.26045 to 0.25689, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 1s/step - accuracy: 0.8008 - loss: 0.4427 - val_accuracy: 1.0000 - val_loss: 0.2569\n",
            "Epoch 21/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7920 - loss: 0.4431\n",
            "Epoch 21: val_loss improved from 0.25689 to 0.25355, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 1s/step - accuracy: 0.7920 - loss: 0.4431 - val_accuracy: 1.0000 - val_loss: 0.2535\n",
            "Epoch 22/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8108 - loss: 0.4321\n",
            "Epoch 22: val_loss improved from 0.25355 to 0.25009, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 1s/step - accuracy: 0.8108 - loss: 0.4321 - val_accuracy: 1.0000 - val_loss: 0.2501\n",
            "Epoch 23/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7995 - loss: 0.4356\n",
            "Epoch 23: val_loss improved from 0.25009 to 0.24686, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.7995 - loss: 0.4357 - val_accuracy: 1.0000 - val_loss: 0.2469\n",
            "Epoch 24/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8006 - loss: 0.4282\n",
            "Epoch 24: val_loss improved from 0.24686 to 0.24509, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.8006 - loss: 0.4282 - val_accuracy: 1.0000 - val_loss: 0.2451\n",
            "Epoch 25/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8084 - loss: 0.4238\n",
            "Epoch 25: val_loss improved from 0.24509 to 0.24112, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 1s/step - accuracy: 0.8084 - loss: 0.4238 - val_accuracy: 1.0000 - val_loss: 0.2411\n",
            "Epoch 26/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8040 - loss: 0.4280\n",
            "Epoch 26: val_loss improved from 0.24112 to 0.23769, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.8040 - loss: 0.4280 - val_accuracy: 1.0000 - val_loss: 0.2377\n",
            "Epoch 27/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7958 - loss: 0.4343\n",
            "Epoch 27: val_loss improved from 0.23769 to 0.23416, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 1s/step - accuracy: 0.7958 - loss: 0.4343 - val_accuracy: 1.0000 - val_loss: 0.2342\n",
            "Epoch 28/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8025 - loss: 0.4349\n",
            "Epoch 28: val_loss improved from 0.23416 to 0.23134, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 1s/step - accuracy: 0.8024 - loss: 0.4348 - val_accuracy: 1.0000 - val_loss: 0.2313\n",
            "Epoch 29/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8034 - loss: 0.4286\n",
            "Epoch 29: val_loss improved from 0.23134 to 0.22874, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.8034 - loss: 0.4287 - val_accuracy: 1.0000 - val_loss: 0.2287\n",
            "Epoch 30/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8134 - loss: 0.4172\n",
            "Epoch 30: val_loss improved from 0.22874 to 0.22596, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 1s/step - accuracy: 0.8133 - loss: 0.4172 - val_accuracy: 1.0000 - val_loss: 0.2260\n",
            "Epoch 31/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8001 - loss: 0.4245\n",
            "Epoch 31: val_loss improved from 0.22596 to 0.22327, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 1s/step - accuracy: 0.8001 - loss: 0.4245 - val_accuracy: 1.0000 - val_loss: 0.2233\n",
            "Epoch 32/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7994 - loss: 0.4257\n",
            "Epoch 32: val_loss improved from 0.22327 to 0.22079, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 1s/step - accuracy: 0.7994 - loss: 0.4257 - val_accuracy: 1.0000 - val_loss: 0.2208\n",
            "Epoch 33/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7994 - loss: 0.4257\n",
            "Epoch 33: val_loss improved from 0.22079 to 0.21852, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 1s/step - accuracy: 0.7994 - loss: 0.4257 - val_accuracy: 1.0000 - val_loss: 0.2185\n",
            "Epoch 34/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8107 - loss: 0.4213\n",
            "Epoch 34: val_loss improved from 0.21852 to 0.21605, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.8107 - loss: 0.4213 - val_accuracy: 1.0000 - val_loss: 0.2160\n",
            "Epoch 35/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8078 - loss: 0.4212\n",
            "Epoch 35: val_loss improved from 0.21605 to 0.21381, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.8078 - loss: 0.4212 - val_accuracy: 1.0000 - val_loss: 0.2138\n",
            "Epoch 36/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8053 - loss: 0.4213\n",
            "Epoch 36: val_loss improved from 0.21381 to 0.21171, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.8053 - loss: 0.4214 - val_accuracy: 1.0000 - val_loss: 0.2117\n",
            "Epoch 37/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7969 - loss: 0.4272\n",
            "Epoch 37: val_loss improved from 0.21171 to 0.20966, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.7969 - loss: 0.4272 - val_accuracy: 1.0000 - val_loss: 0.2097\n",
            "Epoch 38/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8026 - loss: 0.4194\n",
            "Epoch 38: val_loss improved from 0.20966 to 0.20757, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 1s/step - accuracy: 0.8026 - loss: 0.4194 - val_accuracy: 1.0000 - val_loss: 0.2076\n",
            "Epoch 39/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8054 - loss: 0.4199\n",
            "Epoch 39: val_loss improved from 0.20757 to 0.20574, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.8054 - loss: 0.4199 - val_accuracy: 1.0000 - val_loss: 0.2057\n",
            "Epoch 40/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8018 - loss: 0.4186\n",
            "Epoch 40: val_loss improved from 0.20574 to 0.20380, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 1s/step - accuracy: 0.8018 - loss: 0.4186 - val_accuracy: 1.0000 - val_loss: 0.2038\n",
            "Epoch 41/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8053 - loss: 0.4156\n",
            "Epoch 41: val_loss improved from 0.20380 to 0.20187, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.8053 - loss: 0.4156 - val_accuracy: 1.0000 - val_loss: 0.2019\n",
            "Epoch 42/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7977 - loss: 0.4272\n",
            "Epoch 42: val_loss improved from 0.20187 to 0.20014, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.7977 - loss: 0.4272 - val_accuracy: 1.0000 - val_loss: 0.2001\n",
            "Epoch 43/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7944 - loss: 0.4273\n",
            "Epoch 43: val_loss improved from 0.20014 to 0.19865, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 1s/step - accuracy: 0.7944 - loss: 0.4273 - val_accuracy: 1.0000 - val_loss: 0.1986\n",
            "Epoch 44/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8031 - loss: 0.4177\n",
            "Epoch 44: val_loss improved from 0.19865 to 0.19701, saving model to E:/my_models/6000_2_if_new_best_model.weights.h5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 1s/step - accuracy: 0.8031 - loss: 0.4177 - val_accuracy: 1.0000 - val_loss: 0.1970\n",
            "Epoch 45/100\n",
            "\u001b[1m 52/250\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:45\u001b[0m 1s/step - accuracy: 0.8063 - loss: 0.4103"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()\n",
        "\n",
        "# Check regularizers applied to each layer:\n",
        "for layer in model1.layers:\n",
        "    if hasattr(layer, 'kernel_regularizer') and layer.kernel_regularizer is not None:\n",
        "        print(f\"Layer {layer.name} has regularizer: {layer.kernel_regularizer}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "yM7l04d2N-Km",
        "outputId": "f0920530-28e8-4f57-8d53-f440696363ad"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_85 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │      \u001b[38;5;34m52,484,224\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_86 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m3,136\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_56 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m136\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_57 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │      <span style=\"color: #00af00; text-decoration-color: #00af00\">52,484,224</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m157,462,517\u001b[0m (600.67 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">157,462,517</span> (600.67 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,487,505\u001b[0m (200.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,487,505</span> (200.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m104,975,012\u001b[0m (400.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,975,012</span> (400.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer lstm_85 has regularizer: <keras.src.regularizers.regularizers.L2 object at 0x7e449a6c7d60>\n",
            "Layer lstm_86 has regularizer: <keras.src.regularizers.regularizers.L2 object at 0x7e43949bfca0>\n",
            "Layer dense_56 has regularizer: <keras.src.regularizers.regularizers.L2 object at 0x7e47270e7340>\n",
            "Layer dense_57 has regularizer: <keras.src.regularizers.regularizers.L2 object at 0x7e4779f0e8f0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model1.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "y_pred = model1.predict(X_test)\n",
        "y_pred_classes = (y_pred > 0.5).astype(\"int32\")\n",
        "\n",
        "# Evaluate model performance\n",
        "print(classification_report(y_test, y_pred_classes))\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(f\"ROC-AUC: {roc_auc}\")\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color=\"blue\", label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Receiver Operating Characteristic Curve\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Test Accuracy\n",
        "loss, accuracy = model1.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Predictions\n",
        "predictions = model1.predict(X_test).flatten()\n",
        "print(\"\\n🔹 First 10 Predictions vs Actual Values 🔹\")\n",
        "for i in range(10):\n",
        "    print(f\"Sample {i+1}: Actual = {y_test[i]}, Predicted Probability = {predictions[i]:.4f}\")"
      ],
      "metadata": {
        "id": "4i6nANby9Mz2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "352f6661-589f-4895-ca83-41e9f371af33"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - accuracy: 0.9570 - loss: 0.5494\n",
            "Test Accuracy: 0.9605\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      1.00      0.96      1000\n",
            "         1.0       1.00      0.92      0.96      1000\n",
            "\n",
            "    accuracy                           0.96      2000\n",
            "   macro avg       0.96      0.96      0.96      2000\n",
            "weighted avg       0.96      0.96      0.96      2000\n",
            "\n",
            "ROC-AUC: 0.9259999999999999\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - accuracy: 0.9570 - loss: 0.5494\n",
            "Test Accuracy: 0.9605\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step\n",
            "\n",
            "🔹 First 10 Predictions vs Actual Values 🔹\n",
            "Sample 1: Actual = 1.0, Predicted Probability = 0.9999\n",
            "Sample 2: Actual = 0.0, Predicted Probability = 0.4761\n",
            "Sample 3: Actual = 0.0, Predicted Probability = 0.4745\n",
            "Sample 4: Actual = 0.0, Predicted Probability = 0.4782\n",
            "Sample 5: Actual = 0.0, Predicted Probability = 0.4761\n",
            "Sample 6: Actual = 0.0, Predicted Probability = 0.4762\n",
            "Sample 7: Actual = 1.0, Predicted Probability = 0.9999\n",
            "Sample 8: Actual = 1.0, Predicted Probability = 0.9999\n",
            "Sample 9: Actual = 0.0, Predicted Probability = 0.4736\n",
            "Sample 10: Actual = 1.0, Predicted Probability = 0.5124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "explainer = shap.Explainer(model, X_train)\n",
        "explainer = shap.GradientExplainer(model, X_train_combined[:100])\n",
        "# Calculate SHAP values for the input data\n",
        "shap_values = explainer(X_train)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AyfnJHpkXmNx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "5d35e27a-8736-4953-e109-c6a9ef0bc6e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-8d11cc2f60b4>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_combined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Calculate SHAP values for the input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_gradient.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, nsamples)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mExplanation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_gradient.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, nsamples, ranked_outputs, output_rank_order, rseed, return_variances)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \"\"\"\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranked_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_rank_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_variances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_gradient.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, nsamples, ranked_outputs, output_rank_order, rseed, return_variances)\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msamples_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                     \u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_gradient.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, out, model_inputs, X)\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values, input_data)"
      ],
      "metadata": {
        "id": "PRIGEStIX3Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.initjs()  # Initialize JavaScript visualization\n",
        "shap.force_plot(shap_values[0], input_data[0]"
      ],
      "metadata": {
        "id": "8HgckH9gXzt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.dependence_plot(\"feature_name\", shap_values, input_data)"
      ],
      "metadata": {
        "id": "o12ZSZl0X04q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.waterfall_plot(shap_values[0])"
      ],
      "metadata": {
        "id": "85knxzliX2OI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}