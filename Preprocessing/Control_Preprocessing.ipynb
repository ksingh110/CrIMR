{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FqfafHFV01sX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "import random\n",
        "import os\n",
        "import hashlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qwrthST01sZ"
      },
      "source": [
        "Function to fetch CRY1 gene sequence from UCSC API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WsXRLtoN01sb"
      },
      "outputs": [],
      "source": [
        "def get_CRY1_gene():\n",
        "    response = requests.get(\"https://api.genome.ucsc.edu/getData/sequence?genome=hg38;chrom=chr12;start=106991364;end=107093549\")\n",
        "    if response.status_code == 200:\n",
        "        return response.json().get(\"dna\", \"\").upper()\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRgDYCgM01sb"
      },
      "source": [
        "One-hot encode sequence and return a 1D array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DOLR_XZ01sc"
      },
      "outputs": [],
      "source": [
        "def onehotencoder(fasta_sequence, max_length=102500):\n",
        "    sequence_array = np.array(list(fasta_sequence))\n",
        "    label_encoder = LabelEncoder()\n",
        "    integer_encoded = label_encoder.fit_transform(sequence_array)\n",
        "    onehotencoder = OneHotEncoder(sparse_output=False, dtype=np.float32)\n",
        "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "    onehot_sequence = onehotencoder.fit_transform(integer_encoded).astype(np.float32)\n",
        "\n",
        "    if onehot_sequence.shape[0] < max_length:\n",
        "        pad_size = max_length - onehot_sequence.shape[0]\n",
        "        padding = np.zeros((pad_size, onehot_sequence.shape[1]))\n",
        "        onehot_sequence = np.vstack([onehot_sequence, padding])\n",
        "    else:\n",
        "        onehot_sequence = onehot_sequence[:max_length, :]\n",
        "    return onehot_sequence.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr-JJvpQ01sc"
      },
      "source": [
        "Augment sequence by introducing substitutions, deletions, or insertions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGZnNVE901sc"
      },
      "outputs": [],
      "source": [
        "def augment_sequence(seq, mutation_rate=0.1):\n",
        "    \"\"\"\n",
        "    Randomly mutates a subset of the sequence.\n",
        "    - `mutation_rate`: Fraction of positions to mutate (default 10% of sequence).\n",
        "    \"\"\"\n",
        "    random.seed(os.urandom(4))  # Ensure true randomness per sequence\n",
        "\n",
        "    seq_list = list(seq)\n",
        "    num_mutations = int(len(seq_list) * mutation_rate)\n",
        "\n",
        "    for _ in range(num_mutations):\n",
        "        idx = random.randint(0, len(seq_list) - 1)\n",
        "        mutation_type = random.choice([\"substitution\", \"deletion\", \"insertion\"])\n",
        "\n",
        "        if mutation_type == \"substitution\":\n",
        "            seq_list[idx] = random.choice([\"A\", \"G\", \"C\", \"T\"])\n",
        "        elif mutation_type == \"deletion\":\n",
        "            del seq_list[idx]\n",
        "        elif mutation_type == \"insertion\":\n",
        "            seq_list.insert(idx, random.choice([\"A\", \"G\", \"C\", \"T\"]))\n",
        "\n",
        "    return ''.join(seq_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sgj0E0IY01sd"
      },
      "source": [
        "Process augmented sequence and save to output file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WHvHucYv01sd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "43919b23-b637-49b9-ba7d-7c337d721fcb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'augment_sequence' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5552f9f15373>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mcry1_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_CRY1_gene\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcry1_seq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mprocess_data_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcry1_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to fetch CRY1 gene sequence.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-5552f9f15373>\u001b[0m in \u001b[0;36mprocess_data_augmentation\u001b[0;34m(cry1_seq, output_path, num_augmented_sequences, batch_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mseq_count\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_augmented_sequences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0maugmented_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcry1_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Ensure uniqueness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'augment_sequence' is not defined"
          ]
        }
      ],
      "source": [
        "def hash_sequence(sequence):\n",
        "    return hashlib.sha256(sequence.encode()).hexdigest()\n",
        "\n",
        "# Ensure sequence is unique before adding\n",
        "def is_duplicate(sequence, existing_hashes):\n",
        "    return hash_sequence(sequence) in existing_hashes\n",
        "\n",
        "# Process augmented sequences and save to output file\n",
        "def process_data_augmentation(cry1_seq, output_path, num_augmented_sequences=6000, batch_size=250):\n",
        "    \"\"\"\n",
        "    Augments sequences, ensuring diversity, and saves them in batches.\n",
        "    - `num_augmented_sequences`: Total number of augmented sequences to generate.\n",
        "    - `batch_size`: Number of sequences to save in one batch.\n",
        "    \"\"\"\n",
        "    existing_data = []\n",
        "    existing_hashes = set()\n",
        "\n",
        "    # Load existing data if available\n",
        "    if os.path.exists(output_path):\n",
        "        loaded_data = np.load(output_path, allow_pickle=True)[\"arr_0\"].tolist()\n",
        "        existing_data.extend(loaded_data)\n",
        "        existing_hashes.update(hash_sequence(seq) for seq in loaded_data)\n",
        "\n",
        "    seq_count = 0\n",
        "    rows_save = []\n",
        "\n",
        "    while seq_count < num_augmented_sequences:\n",
        "        augmented_seq = augment_sequence(cry1_seq)\n",
        "\n",
        "        # Ensure uniqueness\n",
        "        if not is_duplicate(augmented_seq, existing_hashes):\n",
        "            print(f\"Processed augmented sequence {seq_count + 1}.\")\n",
        "            encoded_seq = onehotencoder(augmented_seq)\n",
        "            seq_count += 1\n",
        "            rows_save.append(encoded_seq)\n",
        "            existing_hashes.add(hash_sequence(augmented_seq))\n",
        "\n",
        "            if len(rows_save) >= batch_size:\n",
        "                existing_data.extend(rows_save)\n",
        "                np.savez_compressed(output_path, arr_0=np.array(existing_data))\n",
        "                rows_save = []\n",
        "\n",
        "    # Save remaining data\n",
        "    if rows_save:\n",
        "        existing_data.extend(rows_save)\n",
        "        np.savez_compressed(output_path, arr_0=np.array(existing_data))\n",
        "\n",
        "    print(f\"Processed {seq_count} augmented sequences and saved to {output_path}.\")\n",
        "\n",
        "# Path to output file\n",
        "output_file = \"AUGMENTED_DATA_TRAINING_6000.npz\"\n",
        "\n",
        "# Fetch CRY1 sequence and process data with augmentation\n",
        "cry1_seq = get_CRY1_gene()\n",
        "if cry1_seq:\n",
        "    process_data_augmentation(cry1_seq, output_file)\n",
        "else:\n",
        "    print(\"Failed to fetch CRY1 gene sequence.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0yY8fler2yb5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4lQaoS001sd"
      },
      "source": [
        "Path to output file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTY2tdJj01se"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLPIAs0a01se"
      },
      "source": [
        "Fetch CRY1 sequence and process data with augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1yS6FsC01se"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonmutated_data = np.load(\"/content/AUGMENTED_DATA_TRAINING_6000_TRUE.npz\", allow_pickle=True)\n",
        "nonmutated_test = nonmutated_data['arr_0'][:1000]\n",
        "output_test = \"AUGMENTED_DATA_TEST_1000_6000\"\n",
        "np.savez_compressed(output_test, arr_0=np.array(nonmutated_test))\n"
      ],
      "metadata": {
        "id": "FNsip4U3finM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonmutated_val = nonmutated_data['arr_0'][5000:]\n",
        "output_val = \"AUGMENTED_DATA_TEST_VAL_1000_6000\"\n",
        "np.savez_compressed(output_val, arr_0=np.array(nonmutated_val))\n"
      ],
      "metadata": {
        "id": "sNYQcnC0hln7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonmutated_train = nonmutated_data['arr_0'][1000:5000]\n",
        "output_train = \"AUGMENTED_DATA_TRAIN_5000_6000\"\n",
        "np.savez_compressed(output_train, arr_0=np.array(nonmutated_train))\n"
      ],
      "metadata": {
        "id": "XYCHe5jWiSlC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import requests\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Hash function to ensure uniqueness\n",
        "def hash_sequence(sequence):\n",
        "    return hashlib.sha256(sequence.encode()).hexdigest()\n",
        "\n",
        "# Ensure sequence is unique before adding\n",
        "def is_duplicate(sequence, existing_hashes):\n",
        "    return hash_sequence(sequence) in existing_hashes\n",
        "\n",
        "# Apply random mutations to a sequence\n",
        "def apply_random_mutations(sequence, mutation_rate=0.05, insertion_rate=0.02, deletion_rate=0.02):\n",
        "    \"\"\"\n",
        "    Apply random mutations to a sequence including substitutions, insertions, and deletions.\n",
        "    - `mutation_rate`: Probability of a nucleotide being substituted.\n",
        "    - `insertion_rate`: Probability of a nucleotide being inserted at a random position.\n",
        "    - `deletion_rate`: Probability of a nucleotide being deleted from a random position.\n",
        "    \"\"\"\n",
        "    seq = list(sequence)  # Convert to a list to modify it\n",
        "\n",
        "    # Substitutions: Replace some nucleotides with random ones\n",
        "    for i in range(len(seq)):\n",
        "        if random.random() < mutation_rate:\n",
        "            seq[i] = random.choice(['A', 'T', 'C', 'G'])  # Randomly choose a nucleotide\n",
        "\n",
        "    # Insertions: Insert random nucleotides at random positions\n",
        "    for _ in range(int(len(seq) * insertion_rate)):  # Insertions based on rate\n",
        "        pos = random.randint(0, len(seq))  # Random position for insertion\n",
        "        seq.insert(pos, random.choice(['A', 'T', 'C', 'G']))  # Insert random nucleotide\n",
        "\n",
        "    # Deletions: Remove nucleotides at random positions\n",
        "    for _ in range(int(len(seq) * deletion_rate)):  # Deletions based on rate\n",
        "        pos = random.randint(0, len(seq) - 1)  # Random position for deletion\n",
        "        del seq[pos]  # Delete nucleotide at the chosen position\n",
        "\n",
        "    return \"\".join(seq)\n",
        "\n",
        "# Add jittering functions\n",
        "def jitter_shift(sequence, max_shift=5):\n",
        "    \"\"\"Shift sequence randomly.\"\"\"\n",
        "    shift = random.randint(-max_shift, max_shift)\n",
        "    return sequence[shift:] + sequence[:shift] if shift >= 0 else sequence[shift:] + sequence[:shift]\n",
        "\n",
        "def jitter_insertion(sequence, max_insertions=3, insertion_rate=0.05):\n",
        "    \"\"\"Insert random nucleotides into the sequence.\"\"\"\n",
        "    seq_list = list(sequence)\n",
        "    for _ in range(int(len(sequence) * insertion_rate)):\n",
        "        pos = random.randint(0, len(seq_list))\n",
        "        seq_list.insert(pos, random.choice(['A', 'T', 'C', 'G']))\n",
        "    return ''.join(seq_list)\n",
        "\n",
        "def jitter_deletion(sequence, max_deletions=3, deletion_rate=0.05):\n",
        "    \"\"\"Delete random nucleotides from the sequence.\"\"\"\n",
        "    seq_list = list(sequence)\n",
        "    for _ in range(int(len(sequence) * deletion_rate)):\n",
        "        pos = random.randint(0, len(seq_list) - 1)\n",
        "        del seq_list[pos]\n",
        "    return ''.join(seq_list)\n",
        "\n",
        "def jitter_substitution(sequence, substitution_rate=0.05):\n",
        "    \"\"\"Substitute random nucleotides in the sequence.\"\"\"\n",
        "    seq_list = list(sequence)\n",
        "    for i in range(len(seq_list)):\n",
        "        if random.random() < substitution_rate:\n",
        "            seq_list[i] = random.choice(['A', 'T', 'C', 'G'])\n",
        "    return ''.join(seq_list)\n",
        "\n",
        "def jitter_rotation(sequence, max_rotation=5):\n",
        "    \"\"\"Randomly rotate the sequence.\"\"\"\n",
        "    rotation = random.randint(1, max_rotation)\n",
        "    return sequence[rotation:] + sequence[:rotation]\n",
        "\n",
        "# Dummy augmentation function\n",
        "def augment_sequence(sequence):\n",
        "    \"\"\"Apply jittering and mutations to the sequence.\"\"\"\n",
        "    sequence = jitter_shift(sequence)\n",
        "    sequence = jitter_insertion(sequence)\n",
        "    sequence = jitter_deletion(sequence)\n",
        "    sequence = jitter_substitution(sequence)\n",
        "    sequence = jitter_rotation(sequence)\n",
        "    return apply_random_mutations(sequence)\n",
        "\n",
        "# One-hot encoding for DNA sequences\n",
        "def onehotencoder(fasta_sequence, max_length=13000):\n",
        "    sequence_array = np.array(list(fasta_sequence))\n",
        "    label_encoder = LabelEncoder()\n",
        "    integer_encoded = label_encoder.fit_transform(sequence_array)\n",
        "    onehotencoder = OneHotEncoder(sparse_output=False, dtype=np.float32)\n",
        "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "    onehot_sequence = onehotencoder.fit_transform(integer_encoded).astype(np.float32)\n",
        "    if onehot_sequence.shape[0] < max_length:\n",
        "        pad_size = max_length - onehot_sequence.shape[0]\n",
        "        padding = np.zeros((pad_size, onehot_sequence.shape[1]))\n",
        "        onehot_sequence = np.vstack([onehot_sequence, padding])\n",
        "    else:\n",
        "        onehot_sequence = onehot_sequence[:max_length, :]\n",
        "    return onehot_sequence.flatten()\n",
        "\n",
        "# Process augmented sequences and save to output file\n",
        "def process_data_augmentation(cry1_seq, output_path, num_augmented_sequences=6000, batch_size=3000):\n",
        "    \"\"\"\n",
        "    Augments sequences, ensuring diversity, and saves them in batches.\n",
        "    - `num_augmented_sequences`: Total number of augmented sequences to generate.\n",
        "    - `batch_size`: Number of sequences to save in one batch.\n",
        "    \"\"\"\n",
        "    existing_data = []\n",
        "    existing_hashes = set()\n",
        "\n",
        "    # Load existing data if available\n",
        "    if os.path.exists(output_path):\n",
        "        loaded_data = np.load(output_path, allow_pickle=True)[\"arr_0\"].tolist()\n",
        "        existing_data.extend(loaded_data)\n",
        "        existing_hashes.update(hash_sequence(seq) for seq in loaded_data)\n",
        "\n",
        "    seq_count = 0\n",
        "    rows_save = []\n",
        "\n",
        "    while seq_count < num_augmented_sequences:\n",
        "        augmented_seq = augment_sequence(cry1_seq)\n",
        "\n",
        "        # Ensure uniqueness\n",
        "        if not is_duplicate(augmented_seq, existing_hashes):\n",
        "            print(f\"Processed augmented sequence {seq_count + 1}.\")\n",
        "            encoded_seq = onehotencoder(augmented_seq)\n",
        "            seq_count += 1\n",
        "            rows_save.append(encoded_seq)\n",
        "            existing_hashes.add(hash_sequence(augmented_seq))\n",
        "\n",
        "            if len(rows_save) >= batch_size:\n",
        "                existing_data.extend(rows_save)\n",
        "                np.savez_compressed(output_path, arr_0=np.array(existing_data))\n",
        "                rows_save = []\n",
        "\n",
        "    # Save remaining data\n",
        "    if rows_save:\n",
        "        existing_data.extend(rows_save)\n",
        "        np.savez_compressed(output_path, arr_0=np.array(existing_data))\n",
        "\n",
        "    print(f\"Processed {seq_count} augmented sequences and saved to {output_path}.\")\n",
        "\n",
        "# Path to output file\n",
        "output_file = \"AUGMENTED_DATA_TRAINING_6000_TRUE.npz\"\n",
        "\n",
        "# Fetch CRY1 sequence and process data with augmentation\n",
        "cry1_seq = get_CRY1_gene()  # Replace with the actual method to fetch your CRY1 sequence\n",
        "if cry1_seq:\n",
        "    process_data_augmentation(cry1_seq, output_file)\n",
        "else:\n",
        "    print(\"Failed to fetch CRY1 gene sequence.\")\n"
      ],
      "metadata": {
        "id": "gLZVnt8PEpWA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}