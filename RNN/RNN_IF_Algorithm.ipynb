{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "83GkxgfIQc7h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import tensorflow as tf\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "# Reset TensorFlow graph\n",
        "tf.compat.v1.reset_default_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXtpL2pKQc7i"
      },
      "source": [
        "Paths and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdQq5widQc7i"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"E:/my_models/750_if_new_best_model.h5\"\n",
        "save_path = \"E:/my_plots/750_if_new_prediction_plots/\"\n",
        "mutated_file = \"/content/MUTATION_DATA_TRAINING_6000.npz\"\n",
        "nonmutated_file = \"/content/AUGMENTED_DATA_TRAINING_6000.npz\"\n",
        "mutated_data = np.load(\"/content/MUTATION_DATA_TRAINING_6000.npz\", allow_pickle=True, mmap_mode='r')\n",
        "nonmutated_data = np.load(\"/content/AUGMENTED_DATA_TRAINING_6000.npz\", allow_pickle=True, mmap_mode='r')\n",
        "csv_file = \"cry1realvariations (1).csv\"  # Assuming this CSV contains mutation data for anomaly detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFTuG0NvQc7j"
      },
      "source": [
        "Anomaly detection using Isolation Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9RSjXZVQc7j"
      },
      "outputs": [],
      "source": [
        "def load_and_get_anomaly_scores(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df = df[df[\"variation_type\"].str.contains(\"intron_variant\", na=False, case=False)]\n",
        "    # Assuming the CSV file has columns 'Mutation ID' and 'Allele Frequency'\n",
        "    data_id_array = df['_displayName'].values[:6000].reshape(-1, 1)  # Get the first 1000 Mutation IDs\n",
        "    array_data = df['AF'].values[:6000].reshape(-1, 1)  # Get the first 1000 Allele Frequencies\n",
        "\n",
        "    # Initialize and fit the Isolation Forest model\n",
        "    clf = IsolationForest(contamination=0.01, random_state=42)\n",
        "    clf.fit(array_data)\n",
        "\n",
        "    # Get anomaly scores and predictions\n",
        "    anomaly_scores = clf.decision_function(array_data)  # Negative scores represent outliers (anomalous)\n",
        "    predictions = clf.predict(array_data)  # -1 for anomaly, 1 for normal\n",
        "\n",
        "    # Invert the anomaly scores (as lower scores indicate anomalies, we invert so higher scores are more \"normal\")\n",
        "    inverted_anomaly_scores = -anomaly_scores\n",
        "\n",
        "    # Filter out NaN values and prepare the data for plotting\n",
        "    valid_indices = ~np.isnan(array_data)\n",
        "    valid_indices = valid_indices.flatten()\n",
        "    data_id_array = data_id_array[valid_indices]\n",
        "    array_data = array_data[valid_indices]\n",
        "    inverted_anomaly_scores = inverted_anomaly_scores[valid_indices]\n",
        "    predictions = predictions[valid_indices]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIo0Ntm4Qc7j"
      },
      "source": [
        "Get anomaly scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T09WczQZQc7j"
      },
      "outputs": [],
      "source": [
        "anomaly_scores, _, _, _ = load_and_get_anomaly_scores(csv_file)\n",
        "def load_data_in_batches(file_path, batch_size=1000):\n",
        "    data = np.load(file_path, allow_pickle=True, mmap_mode='r')\n",
        "    keys = list(data.files)\n",
        "    for i in range(0, len(keys), batch_size):\n",
        "        batch_keys = keys[i:i+batch_size]\n",
        "        batch_data = [data[key] for key in batch_keys]\n",
        "        yield np.array(batch_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvTcb_ZPQc7j"
      },
      "source": [
        "Function to load sequences and their labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAqDxD17Qc7j"
      },
      "outputs": [],
      "source": [
        "def load_sequences(data, label, file_path, batch_size=1000):\n",
        "    encoded_sequences = None\n",
        "    input_shape = None\n",
        "    data_load = load_data_in_batches(file_path, batch_size=batch_size)  # Getting batches\n",
        "\n",
        "    for batch_data in data_load:  # Iterating through the batches\n",
        "        temp_sequences = batch_data  # This is the data for the current batch\n",
        "        print(f\"Batch shape: {temp_sequences.shape}\")  # Debugging\n",
        "\n",
        "        if temp_sequences.ndim == 2:  # If 2D, reshape to 3D for LSTM\n",
        "            temp_sequences = np.expand_dims(temp_sequences, axis=1)  # (samples, 1, features)\n",
        "\n",
        "        if temp_sequences.ndim == 3:\n",
        "            encoded_sequences = temp_sequences\n",
        "            input_shape = (encoded_sequences.shape[1], encoded_sequences.shape[2])\n",
        "            print(f\"Using batch with reshaped shape {encoded_sequences.shape}\")\n",
        "            break\n",
        "        else:\n",
        "            print(f\"Skipping batch: Unexpected shape {temp_sequences.shape}\")\n",
        "\n",
        "    if encoded_sequences is None:\n",
        "        raise ValueError(f\"No valid encoded sequences found in {label} file.\")\n",
        "\n",
        "    return encoded_sequences, input_shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as5fPxMEQc7k"
      },
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNDWtI4pQc7k",
        "outputId": "7f1643c5-1cf5-409c-aa22-83e565dd6a33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: (1, 6000, 410000)\n",
            "Using batch with reshaped shape (1, 6000, 410000)\n",
            "Batch shape: (1, 6000, 410000)\n",
            "Using batch with reshaped shape (1, 6000, 410000)\n"
          ]
        }
      ],
      "source": [
        "mutated_sequences, input_shape = load_sequences(mutated_data, \"mutated\", mutated_file)\n",
        "nonmutated_sequences, _ = load_sequences(nonmutated_data, \"nonmutated\", nonmutated_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iahiovvKQc7k"
      },
      "outputs": [],
      "source": [
        "mutated_labels = np.ones(mutated_sequences.shape[0])  # 1 for mutated\n",
        "nonmutated_labels = np.zeros(nonmutated_sequences.shape[0])  # 0 for non-mutated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfHDzl9iQc7k"
      },
      "source": [
        "Step 1: Generate random Mutation IDs for non-mutated data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25nNlt7GQc7k"
      },
      "outputs": [],
      "source": [
        "nonmutated_data_with_ids = np.array([f\"NonMut_{i}\" for i in range(len(nonmutated_data.files))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKT7pzVvQc7k"
      },
      "source": [
        "Step 2: Add noise to the Allele Frequency for the non-mutated data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssJPT-e8Qc7k"
      },
      "outputs": [],
      "source": [
        "allele_frequency_mutated = pd.read_csv(csv_file)['AF'].values[:6000]  # Allele Frequency of mutated data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JTeebY3Qc7l"
      },
      "source": [
        "Generate random noise (Gaussian noise with mean 0 and std deviation same as mutated data's AF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EknyDe9HQc7l"
      },
      "outputs": [],
      "source": [
        "noise = np.random.normal(0, np.std(allele_frequency_mutated), len(nonmutated_data.files))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwoWT9v6Qc7l"
      },
      "source": [
        "Add noise to non-mutated allele frequencies (assuming a similar structure in 'nonmutated_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PmpAi8tQc7l"
      },
      "outputs": [],
      "source": [
        "nonmutated_allele_frequency = np.random.normal(np.mean(allele_frequency_mutated), np.std(allele_frequency_mutated), len(nonmutated_data.files))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMLU7VYcQc7l"
      },
      "source": [
        "Step 3: Incorporate noise into non-mutated data for Isolation Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si4FFx6dQc7l"
      },
      "outputs": [],
      "source": [
        "df_nonmutated_with_noise = pd.DataFrame({\n",
        "    '_displayName': nonmutated_data_with_ids,\n",
        "    'AF': nonmutated_allele_frequency\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl_n-2wGQc7l"
      },
      "source": [
        "Step 4: Apply Isolation Forest on non-mutated data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPIPsDgoQc7l",
        "outputId": "c6aa73c6-b611-45e8-8dea-6b518e97a279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IsolationForest(contamination=0.01, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IsolationForest(contamination=0.01, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>IsolationForest</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.IsolationForest.html\">?<span>Documentation for IsolationForest</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>IsolationForest(contamination=0.01, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "clf = IsolationForest(contamination=0.01, random_state=42)\n",
        "clf.fit(df_nonmutated_with_noise['AF'].values.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I7UlPhWQc7l"
      },
      "source": [
        "Get anomaly scores and predictions for non-mutated data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Toh8xlhQQc7l"
      },
      "outputs": [],
      "source": [
        "nonmutated_anomaly_scores = clf.decision_function(df_nonmutated_with_noise['AF'].values.reshape(-1, 1))\n",
        "nonmutated_predictions = clf.predict(df_nonmutated_with_noise['AF'].values.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rratmviuQc7l"
      },
      "source": [
        "Invert the anomaly scores (lower scores = anomalies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr5GVJZIQc7l"
      },
      "outputs": [],
      "source": [
        "nonmutated_inverted_anomaly_scores = -nonmutated_anomaly_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFKB8JMYQc7l"
      },
      "source": [
        "Append anomaly scores to features (only for the mutated sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkeF_APSQc7m"
      },
      "outputs": [],
      "source": [
        "anomaly_scores_reshaped = anomaly_scores[:mutated_sequences.shape[0]].reshape(-1, 1)\n",
        "# Expand anomaly_scores_reshaped to 3D (1000, 1, 1) to match the timesteps axis of X\n",
        "anomaly_scores_reshaped = np.expand_dims(anomaly_scores_reshaped, axis=-1)  # shape (1000, 1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CLrQBkNQc7m"
      },
      "source": [
        "Update the last feature of each sequence with the anomaly score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFEvb6t7Qc7m"
      },
      "outputs": [],
      "source": [
        "mutated_sequences_with_anomalies = mutated_sequences.copy()  # Make a copy of mutated_sequences\n",
        "mutated_sequences_with_anomalies[:, :, -1:] = anomaly_scores_reshaped  # Replace the last feature with the anomaly score\n",
        "# Concatenate anomaly scores with mutated sequences only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5GmeJklQc7m"
      },
      "source": [
        "Concatenate the mutated and non-mutated sequences (with anomalies added to mutated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqxP6tycQc7m"
      },
      "outputs": [],
      "source": [
        "X_with_anomalies = np.concatenate([mutated_sequences_with_anomalies, nonmutated_sequences], axis=0)\n",
        "y = np.concatenate([mutated_labels, nonmutated_labels], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sudu4Y5zQc7m",
        "outputId": "c429537b-9c9e-4dc2-aedd-dcd344f2ef9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-e7dd1251e447>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_with_anomalies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2870\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2872\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_common_namespace_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1907\u001b[0m         \"\"\"\n\u001b[1;32m   1908\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1909\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1910\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2318\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2319\u001b[0m                 \u001b[0;34m\"The least populated class in y has only 1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m                 \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
          ]
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_with_anomalies, y, random_state=42, test_size=0.2, stratify=y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feTxpb44Qc7m"
      },
      "source": [
        "RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4Z2pPqnQc7m"
      },
      "outputs": [],
      "source": [
        "def rnn_model(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(32, input_shape=input_shape, return_sequences=False, activation=\"relu\"),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "    ])\n",
        "    model.compile(optimizer=\"adamw\", loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vug8AfrQc7m"
      },
      "outputs": [],
      "source": [
        "def reset_rnn(input_shape):\n",
        "    # Recreate the model to reset weights\n",
        "    model = rnn_model(input_shape)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcbBuiapQc7m"
      },
      "source": [
        "Plotting function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFLJQPeSQc7q"
      },
      "outputs": [],
      "source": [
        "def plot_learning_curve(history, save_path):\n",
        "    # Extract training and validation loss (or accuracy)\n",
        "    training_loss = history.history['loss']\n",
        "    validation_loss = history.history['val_loss']\n",
        "    training_acc = history.history['accuracy']\n",
        "    validation_acc = history.history['val_accuracy']\n",
        "    epochs = range(1, len(training_loss) + 1)\n",
        "\n",
        "    # Plot loss curves\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Loss plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, training_loss, label='Training Loss')\n",
        "    plt.plot(epochs, validation_loss, label='Validation Loss')\n",
        "    plt.title('Loss Curve')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, training_acc, label='Training Accuracy')\n",
        "    plt.plot(epochs, validation_acc, label='Validation Accuracy')\n",
        "    plt.title('Accuracy Curve')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAugG9NjQc7q"
      },
      "source": [
        "Reset model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZLbWioKQc7q"
      },
      "outputs": [],
      "source": [
        "model = reset_rnn(input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQcWTJbnQc7q"
      },
      "source": [
        "Checkpoints and logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0RJcDNcQc7q"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor=\"val_loss\", save_best_only=True, mode=\"min\")\n",
        "csv_log = CSVLogger(\"training_log_new_750_if.csv\", append=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss9sIuP5Qc7q"
      },
      "source": [
        "Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnBGhTI0Qc7q"
      },
      "outputs": [],
      "source": [
        "rnn_fit = model.fit(x_train, y_train, batch_size=16, epochs=20, verbose=1, validation_data=(x_test, y_test), callbacks=[csv_log, checkpoint])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5fiBMzDQc7r"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "460wFmC4Qc7r"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX3SrCo0Qc7r"
      },
      "source": [
        "Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57HjQF1oQc7r"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(x_test).flatten()\n",
        "print(\"\\nðŸ”¹ First 10 Predictions vs Actual Values ðŸ”¹\")\n",
        "for i in range(10):\n",
        "    print(f\"Sample {i+1}: Actual = {y_test[i]}, Predicted Probability = {predictions[i]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWgtNkELQc7r"
      },
      "source": [
        "Save plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkamU7kdQc7r"
      },
      "outputs": [],
      "source": [
        "os.makedirs(save_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW9OZ7QtQc7r"
      },
      "source": [
        "Histogram of predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKLjHX8KQc7r"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "plt.hist(predictions, bins=20, edgecolor='black', alpha=0.7)\n",
        "plt.xlabel(\"Predicted Probability\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Predicted Probabilities\")\n",
        "plt.savefig(save_path + \"histogram_predictions.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zkDDvDYQc7r"
      },
      "source": [
        "Calculate the ROC curve and AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQ1MSUmQQc7s"
      },
      "outputs": [],
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
        "roc_auc = roc_auc_score(y_test, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWVRg52cQc7s"
      },
      "source": [
        "Plot ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP7GCP1dQc7s"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig(save_path + \"750_new_if_roc_curve.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDVz0KGHQc7s"
      },
      "outputs": [],
      "source": [
        "print(f\"Area Under the Curve (AUC): {roc_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMVH4r8BQc7s"
      },
      "source": [
        "Classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJQDdFlbQc7s"
      },
      "outputs": [],
      "source": [
        "report = classification_report(y_test, (predictions > 0.5).astype(int))\n",
        "print(\"\\nClassification Report:\" + report)\n",
        "report = classification_report(y_test, (predictions > 0.5).astype(int), output_dict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gylJHe3Qc7s"
      },
      "source": [
        "Convert the dictionary into a DataFrame and transpose it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWEzFpicQc7s"
      },
      "outputs": [],
      "source": [
        "report_df = pd.DataFrame(report).transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNGI5bZaQc7s"
      },
      "source": [
        "Save the report to a CSV file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZzw2mZqQc7s"
      },
      "outputs": [],
      "source": [
        "report_df.to_csv(\"750_new_if_classification_report.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6djDQ9gQc7s"
      },
      "source": [
        "Plot learning curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ceb5uuDQc7t"
      },
      "outputs": [],
      "source": [
        "plot_learning_curve(rnn_fit, save_path=\"750_new_if_learning_curve\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import tensorflow as tf\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "# Reset TensorFlow graph\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "# Paths and data\n",
        "checkpoint_path = \"E:/my_models/750_if_new_best_model.h5\"\n",
        "save_path = \"E:/my_plots/750_if_new_prediction_plots/\"\n",
        "mutated_data = np.load(\"/content/MUTATION_DATA_TRAINING_6000.npz\", allow_pickle=True, mmap_mode='r')\n",
        "nonmutated_data = np.load(\"/content/AUGMENTED_DATA_TRAINING_6000.npz\", allow_pickle=True, mmap_mode='r')\n",
        "csv_file = \"cry1realvariations (1).csv\"  # Assuming this CSV contains mutation data for anomaly detection\n",
        "\n",
        "# Anomaly detection using Isolation Forest\n",
        "def load_and_get_anomaly_scores(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df = df[df[\"variation_type\"].str.contains(\"intron_variant\", na=False, case=False)]\n",
        "    # Assuming the CSV file has columns 'Mutation ID' and 'Allele Frequency'\n",
        "    data_id_array = df['_displayName'].values[:6000].reshape(-1, 1)  # Get the first 1000 Mutation IDs\n",
        "    array_data = df['AF'].values[:6000].reshape(-1, 1)  # Get the first 1000 Allele Frequencies\n",
        "\n",
        "    # Initialize and fit the Isolation Forest model\n",
        "    clf = IsolationForest(contamination=0.01, random_state=42)\n",
        "    clf.fit(array_data)\n",
        "\n",
        "    # Get anomaly scores and predictions\n",
        "    anomaly_scores = clf.decision_function(array_data)  # Negative scores represent outliers (anomalous)\n",
        "    predictions = clf.predict(array_data)  # -1 for anomaly, 1 for normal\n",
        "\n",
        "    # Invert the anomaly scores (as lower scores indicate anomalies, we invert so higher scores are more \"normal\")\n",
        "    inverted_anomaly_scores = -anomaly_scores\n",
        "\n",
        "    # Filter out NaN values and prepare the data for plotting\n",
        "    valid_indices = ~np.isnan(array_data)\n",
        "    valid_indices = valid_indices.flatten()\n",
        "    data_id_array = data_id_array[valid_indices]\n",
        "    array_data = array_data[valid_indices]\n",
        "    inverted_anomaly_scores = inverted_anomaly_scores[valid_indices]\n",
        "    predictions = predictions[valid_indices]\n",
        "\n",
        "    return inverted_anomaly_scores, data_id_array, array_data, predictions\n",
        "\n",
        "# Get anomaly scores\n",
        "anomaly_scores, _, _, _ = load_and_get_anomaly_scores(csv_file)\n",
        "\n",
        "# Function to load sequences and their labels\n",
        "def load_sequences(data, label):\n",
        "    encoded_sequences = None\n",
        "    input_shape = None\n",
        "\n",
        "    for key in data.files:\n",
        "        temp_sequences = data[key]\n",
        "        print(f\"Checking key '{key}': shape {temp_sequences.shape}\")  # Debugging\n",
        "\n",
        "        if temp_sequences.ndim == 2:  # If 2D, reshape to 3D for LSTM\n",
        "            temp_sequences = np.expand_dims(temp_sequences, axis=1)  # (samples, 1, features)\n",
        "\n",
        "        if temp_sequences.ndim == 3:\n",
        "            encoded_sequences = temp_sequences\n",
        "            input_shape = (encoded_sequences.shape[1], encoded_sequences.shape[2])\n",
        "            print(f\"Using key '{key}' with reshaped shape {encoded_sequences.shape}\")\n",
        "            break\n",
        "        else:\n",
        "            print(f\"Skipping '{key}': Unexpected shape {temp_sequences.shape}\")\n",
        "\n",
        "    if encoded_sequences is None:\n",
        "        raise ValueError(f\"No valid encoded sequences found in {label} file.\")\n",
        "\n",
        "    return encoded_sequences, input_shape\n",
        "\n",
        "# Load data\n",
        "mutated_sequences, input_shape = load_sequences(mutated_data, \"mutated\")\n",
        "nonmutated_sequences, _ = load_sequences(nonmutated_data, \"nonmutated\")\n",
        "\n",
        "mutated_labels = np.ones(mutated_sequences.shape[0])  # 1 for mutated\n",
        "nonmutated_labels = np.zeros(nonmutated_sequences.shape[0])  # 0 for non-mutated\n",
        "\n",
        "# Step 1: Generate random Mutation IDs for non-mutated data\n",
        "nonmutated_data_with_ids = np.array([f\"NonMut_{i}\" for i in range(len(nonmutated_data.files))])\n",
        "\n",
        "# Step 2: Add noise to the Allele Frequency for the non-mutated data\n",
        "allele_frequency_mutated = pd.read_csv(csv_file)['AF'].values[:6000]  # Allele Frequency of mutated data\n",
        "\n",
        "# Generate random noise (Gaussian noise with mean 0 and std deviation same as mutated data's AF)\n",
        "noise = np.random.normal(0, np.std(allele_frequency_mutated), len(nonmutated_data.files))\n",
        "\n",
        "# Add noise to non-mutated allele frequencies (assuming a similar structure in 'nonmutated_data')\n",
        "nonmutated_allele_frequency = np.random.normal(np.mean(allele_frequency_mutated), np.std(allele_frequency_mutated), len(nonmutated_data.files))\n",
        "\n",
        "# Step 3: Incorporate noise into non-mutated data for Isolation Forest\n",
        "df_nonmutated_with_noise = pd.DataFrame({\n",
        "    '_displayName': nonmutated_data_with_ids,\n",
        "    'AF': nonmutated_allele_frequency\n",
        "})\n",
        "\n",
        "# Step 4: Apply Isolation Forest on non-mutated data\n",
        "clf = IsolationForest(contamination=0.01, random_state=42)\n",
        "clf.fit(df_nonmutated_with_noise['AF'].values.reshape(-1, 1))\n",
        "\n",
        "# Get anomaly scores and predictions for non-mutated data\n",
        "nonmutated_anomaly_scores = clf.decision_function(df_nonmutated_with_noise['AF'].values.reshape(-1, 1))\n",
        "nonmutated_predictions = clf.predict(df_nonmutated_with_noise['AF'].values.reshape(-1, 1))\n",
        "\n",
        "# Invert the anomaly scores (lower scores = anomalies)\n",
        "nonmutated_inverted_anomaly_scores = -nonmutated_anomaly_scores\n",
        "\n",
        "# Append anomaly scores to features (only for the mutated sequences)\n",
        "anomaly_scores_reshaped = anomaly_scores[:mutated_sequences.shape[0]].reshape(-1, 1)\n",
        "# Expand anomaly_scores_reshaped to 3D (1000, 1, 1) to match the timesteps axis of X\n",
        "anomaly_scores_reshaped = np.expand_dims(anomaly_scores_reshaped, axis=-1)  # shape (1000, 1, 1)\n",
        "\n",
        "# Update the last feature of each sequence with the anomaly score\n",
        "mutated_sequences_with_anomalies = mutated_sequences.copy()  # Make a copy of mutated_sequences\n",
        "mutated_sequences_with_anomalies[:, :, -1:] = anomaly_scores_reshaped  # Replace the last feature with the anomaly score\n",
        "# Concatenate anomaly scores with mutated sequences only\n",
        "\n",
        "# Concatenate the mutated and non-mutated sequences (with anomalies added to mutated)\n"
      ],
      "metadata": {
        "id": "MtMHBJ4naiI5",
        "outputId": "1b79a28c-901e-4d28-f156-e023eb094218",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking key 'arr_0': shape (6000, 410000)\n",
            "Using key 'arr_0' with reshaped shape (6000, 1, 410000)\n",
            "Checking key 'arr_0': shape (6000, 410000)\n",
            "Using key 'arr_0' with reshaped shape (6000, 1, 410000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"E:/my_models/750_if_new_best_model.keras\""
      ],
      "metadata": {
        "id": "eBYB0UzPGiIq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_with_anomalies = np.concatenate([mutated_sequences_with_anomalies, nonmutated_sequences], axis=0)\n",
        "y = np.concatenate([mutated_labels, nonmutated_labels], axis=0)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# First, split off the test set (10%)\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X_with_anomalies, y, test_size=0.1, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Then, split the remaining data into train (80%) and validation (10%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.1 / 0.9, random_state=42, stratify=y_train_val\n",
        ")\n",
        "\n",
        "# Now we have 80% training, 10% validation, and 10% test\n",
        "\n",
        "\n",
        "# RNN Model\n",
        "def rnn_model(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(32, input_shape=input_shape, return_sequences=False, activation=\"relu\"),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "    ])\n",
        "    model.compile(optimizer=\"adamw\", loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def reset_rnn(input_shape):\n",
        "    # Recreate the model to reset weights\n",
        "    model = rnn_model(input_shape)\n",
        "    return model\n",
        "\n",
        "# Plotting function\n",
        "def plot_learning_curve(history, save_path):\n",
        "    # Extract training and validation loss (or accuracy)\n",
        "    training_loss = history.history['loss']\n",
        "    validation_loss = history.history['val_loss']\n",
        "    training_acc = history.history['accuracy']\n",
        "    validation_acc = history.history['val_accuracy']\n",
        "\n",
        "    epochs = range(1, len(training_loss) + 1)\n",
        "\n",
        "    # Plot loss curves\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Loss plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, training_loss, label='Training Loss')\n",
        "    plt.plot(epochs, validation_loss, label='Validation Loss')\n",
        "    plt.title('Loss Curve')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, training_acc, label='Training Accuracy')\n",
        "    plt.plot(epochs, validation_acc, label='Validation Accuracy')\n",
        "    plt.title('Accuracy Curve')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "\n",
        "# Reset model\n",
        "model = reset_rnn(input_shape)\n",
        "\n",
        "# Checkpoints and logging\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor=\"val_loss\", save_best_only=True, mode=\"min\")\n",
        "csv_log = CSVLogger(\"training_log_new_750_if.csv\", append=True)\n",
        "\n",
        "# Fit the model\n",
        "rnn_fit = model.fit(x_train, y_train, batch_size=16, epochs=20, verbose=1, validation_data=(x_test, y_test), callbacks=[csv_log, checkpoint])\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Predictions\n",
        "predictions = model.predict(x_test).flatten()\n",
        "print(\"\\n🔹 First 10 Predictions vs Actual Values 🔹\")\n",
        "for i in range(10):\n",
        "    print(f\"Sample {i+1}: Actual = {y_test[i]}, Predicted Probability = {predictions[i]:.4f}\")\n",
        "\n",
        "# Save plots\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Histogram of predictions\n",
        "plt.figure(figsize=(14, 10))\n",
        "plt.hist(predictions, bins=20, edgecolor='black', alpha=0.7)\n",
        "plt.xlabel(\"Predicted Probability\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Predicted Probabilities\")\n",
        "plt.savefig(save_path + \"histogram_predictions.png\")\n",
        "plt.show()\n",
        "\n",
        "# Calculate the ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
        "roc_auc = roc_auc_score(y_test, predictions)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig(save_path + \"750_new_if_roc_curve.png\")\n",
        "\n",
        "print(f\"Area Under the Curve (AUC): {roc_auc:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "report = classification_report(y_test, (predictions > 0.5).astype(int))\n",
        "print(\"\\nClassification Report:\" + report)\n",
        "report = classification_report(y_test, (predictions > 0.5).astype(int), output_dict=True)\n",
        "\n",
        "# Convert the dictionary into a DataFrame and transpose it\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Save the report to a CSV file\n",
        "report_df.to_csv(\"750_new_if_classification_report.csv\")\n",
        "\n",
        "# Plot learning curves\n",
        "plot_learning_curve(rnn_fit, save_path=\"750_new_if_learning_curve\")\n"
      ],
      "metadata": {
        "id": "_h56cAHcbDY7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}