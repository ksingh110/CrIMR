{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import requests\n", "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n", "import random\n", "import os"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Function to fetch CRY1 gene sequence from UCSC API"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_CRY1_gene():\n", "    response = requests.get(\"https://api.genome.ucsc.edu/getData/sequence?genome=hg38;chrom=chr12;start=106991364;end=107093549\")\n", "    if response.status_code == 200:\n", "        return response.json().get(\"dna\", \"\").upper()\n", "    else:\n", "        return None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["One-hot encode sequence and return a 1D array"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def onehotencoder(fasta_sequence, max_length=102500):\n", "    sequence_array = np.array(list(fasta_sequence))\n", "    label_encoder = LabelEncoder()\n", "    integer_encoded = label_encoder.fit_transform(sequence_array)\n", "    onehotencoder = OneHotEncoder(sparse_output=False, dtype=np.float32)\n", "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n", "    onehot_sequence = onehotencoder.fit_transform(integer_encoded).astype(np.float32)\n", "    \n", "    if onehot_sequence.shape[0] < max_length:\n", "        pad_size = max_length - onehot_sequence.shape[0]\n", "        padding = np.zeros((pad_size, onehot_sequence.shape[1]))\n", "        onehot_sequence = np.vstack([onehot_sequence, padding])\n", "    else:\n", "        onehot_sequence = onehot_sequence[:max_length, :]\n", "    return onehot_sequence.flatten()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Augment sequence by introducing substitutions, deletions, or insertions"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def augment_sequence(seq, substitution_prob=0.33, deletion_prob=0.33, insertion_prob=0.33):\n", "    augmented_seq = list(seq)\n", "    seq_len = len(augmented_seq)\n", "    for i in range(seq_len):\n", "        # Substitution\n", "        if random.random() < substitution_prob:\n", "            augmented_seq[i] = random.choice(['A', 'G', 'C', 'T'])\n", "        \n", "        # Deletion\n", "        elif random.random() < deletion_prob:\n", "            augmented_seq[i] = ''\n", "        \n", "        # Insertion\n", "        elif random.random() < insertion_prob:\n", "            augmented_seq.insert(i, random.choice(['A', 'G', 'C', 'T']))\n", "            seq_len += 1  # Increase sequence length after insertion\n", "            i += 1  # Skip the next index after insertion to avoid double counting\n\n", "    # Join the list back to a string after mutation\n", "    augmented_seq = ''.join(augmented_seq)\n", "    return augmented_seq"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Process augmented sequence and save to output file"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def process_data_augmentation(cry1_seq, output_path, num_augmented_sequences=1250):\n", "    # Initialize existing data for appending\n", "    if os.path.exists(output_path):\n", "        existing_data = np.load(output_path, allow_pickle=True)[\"arr_0\"].tolist()\n", "    else:\n", "        existing_data = []\n", "    seq_count = 0\n", "    batch = 250\n", "    rows_save = []\n\n", "    # Generate augmented sequences and save\n", "    while seq_count < num_augmented_sequences:\n", "        # Augment the sequence\n", "        augmented_seq = augment_sequence(cry1_seq)\n", "        print(f\"Processed augmented sequence {seq_count + 1}.\")\n", "        if augmented_seq:\n", "            encoded_seq = onehotencoder(augmented_seq)\n", "            seq_count += 1\n", "            rows_save.append(encoded_seq)\n", "            if len(rows_save) >= batch:\n", "                existing_data.extend(rows_save)\n", "                np.savez_compressed(output_path, arr_0=np.array(existing_data))\n", "                rows_save = []\n", "    if rows_save:\n", "        existing_data.extend(rows_save)\n", "        np.savez_compressed(output_path, arr_0=np.array(existing_data))\n", "    \n", "    print(f\"Processed {seq_count} augmented sequences and saved to {output_path}.\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Path to output file"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["output_file = \"E:\\\\datasets\\\\processeddata\\\\AUGMENTED_DATA_TRAINING_1250_NEW.npz\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Fetch CRY1 sequence and process data with augmentation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cry1_seq = get_CRY1_gene()\n", "if cry1_seq:\n", "    process_data_augmentation(cry1_seq, output_file)\n", "else:\n", "    print(\"Failed to fetch CRY1 gene sequence.\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}